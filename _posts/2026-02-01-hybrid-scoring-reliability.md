---
title: "New Publication: Reliability of Hybrid Human-ML Scoring Systems"
date: 2026-02-01
categories:
  - Research
  - Publications
tags:
  - Psychometrics
  - Machine Learning
  - IRT
  - Many-Facet Rasch Model
---

[cite_start]I am pleased to share that our new paper, **"Revisiting reliability with human and machine learning raters under scoring design and rater configuration in the many-facet Rasch model,"** has been published in the *British Journal of Mathematical and Statistical Psychology*[cite: 4, 744].

[cite_start]This research, conducted with co-authors Richard J. Patz and Mark R. Wilson, investigates the psychometric impact of integrating machine learning (ML) scoring into high-stakes assessment frameworks[cite: 5, 17, 18].

### **Key Insights**
* [cite_start]**Systematic Bias vs. Noise:** We found that systematic rater bias, rather than random machine inconsistency, is the primary driver of estimation error in hybrid scoring systems[cite: 21, 80, 633].
* [cite_start]**Design Density:** Increasing scoring matrix density (moving from isolated to complete designs) significantly stabilizes latent proficiency recovery[cite: 23, 350, 546].
* [cite_start]**Strategic Hybridization:** Hybrid scoring yields the greatest reliability gains when human and ML raters possess **opposing biases**, allowing directional errors to cancel out[cite: 22, 618, 620].
* [cite_start]**Robust Modeling:** For sparse scoring designs, the Partial Credit Model (PCM) with fixed thresholds often outperforms more complex Many-Facet variants by reducing over-parameterization[cite: 23, 499, 646].



### **Practical Application**
[cite_start]We applied these findings to real-world data from a "Problem Solving with Math" (PSM) assessment[cite: 73, 275]. [cite_start]Results confirmed that anchoring constructed-response items to selected-response metrics can effectively stabilize scales in sparse scoring environments[cite: 82, 648].

**Full Citation:**
Xiao, X., Patz, R. J., & Wilson, M. R. (2026). Revisiting reliability with human and machine learning raters under scoring design and rater configuration in the many-facet Rasch model. *British Journal of Mathematical and Statistical Psychology*. [cite_start][https://doi.org/10.1111/bmsp.70034](https://doi.org/10.1111/bmsp.70034) [cite: 742, 744]
