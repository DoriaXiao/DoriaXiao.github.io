---
title: "Research"
permalink: /research/
---

[cite_start]My research operates at the intersection of **statistical methodology** and **educational technology**, developing robust psychometric frameworks for high-stakes digital assessments. [cite_start]I specialize in **Bayesian longitudinal modeling** and the integration of machine learning into measurement.

### Current Research Themes

#### **1. AI-Integrated Measurement & Hybrid Scoring**
[cite_start]I investigate how machine learning (ML) scoring can scale constructed-response assessments when integrated with human judgment. 
* [cite_start]My recent work shows that **systematic rater bias** is a greater threat to reliability than random machine noise[cite: 2].
* [cite_start]I have identified a **"bias compensation"** mechanism: pairing ML models with human raters of opposing severity profiles can cancel out directional errors and restore accuracy[cite: 2].
* [cite_start]This research supports using the **Many-Facet Rasch Model (MFRM)** and anchoring strategies to stabilize scales in sparse scoring designs[cite: 2].



#### **2. Bayesian Longitudinal & Growth Mixture Modeling (GMM)**
[cite_start]A core focus is the stability and evaluation of latent variable models.
* [cite_start]I develop Bayesian diagnostics to identify local identifiability issues and convergence failures in growth mixture models.
* [cite_start]My work utilizes marginal likelihood to compare model selection strategies for longitudinal behavioral change.



#### **3. Global Development (LEVANTE Project)**
[cite_start]At Stanford, I work on the **LEVANTE project** to create internationalized measures of learning for children aged 5–12.
* [cite_start]I focus on **measurement invariance** and statistical methods for modeling developmental change across cultural contexts.
* [cite_start]We aim to validate core cognitive tasks that remain robust across languages and research sites.

#### **4. Adaptive Measurement & Digital Innovation**
* [cite_start]**CAT Fairness**: Researching calibration error mitigation and robust stopping rules in computer-adaptive testing.
* **Silver Tech**: Applying psychometric principles to the development of **"Silver Hair"** (银发产品) digital solutions for the aging population.

---

### Methods & Technical Toolbelt

[cite_start]I lean heavily on open-science and "GitHub-first" workflows to solve measurement challenges.

* [cite_start]**Models**: Multidimensional IRT (mIRT), Many-Facet Rasch Models (MFRM), Bayesian GMM, and Differential Item Functioning (DIF).
* [cite_start]**AI/NLP**: LLM evaluation (GPT-4), NLP-based scoring frameworks, and automated prompt engineering.
* [cite_start]**Statistical Software**: Expert proficiency in **R** (Stan, ggplot2, Shiny), **Python**, SQL, and **Mplus**.
* [cite_start]**Reproducibility**: Quarto, LaTeX, and Git/GitHub version control.
