---
title: "Research"
permalink: /research/
---

[cite_start]My research focuses on the intersection of **statistical methodology** and **educational technology**, specifically developing robust psychometric frameworks for high-stakes digital assessments[cite: 1]. [cite_start]I specialize in Bayesian longitudinal modeling and the integration of machine learning into traditional measurement models[cite: 1, 2].

### Current Research Themes

#### **1. AI-Integrated Measurement & Hybrid Scoring**
[cite_start]I investigate how machine learning (ML) scoring can be integrated with human judgment to improve the scalability of constructed-response items[cite: 1, 2]. 
* [cite_start]My recent work demonstrates that systematic rater bias is a greater threat to reliability than random machine noise[cite: 2].
* [cite_start]I have identified a "bias compensation" mechanism where pairing ML models with humans of opposing severity profiles can cancel out directional errors and restore estimation accuracy[cite: 2].
* [cite_start]This research advocates for using the **Many-Facet Rasch Model (MFRM)** and anchoring strategies to stabilize scales in sparse scoring environments[cite: 2].



#### **2. Bayesian Longitudinal & Growth Mixture Modeling (GMM)**
[cite_start]A core part of my methodological work involves the identification and estimation stability of latent variable models[cite: 1].
* [cite_start]I develop Bayesian diagnostics to identify local identifiability issues and convergence failures in growth mixture models[cite: 1].
* [cite_start]My research utilizes marginal likelihood and simulation-based evaluation to compare model selection strategies for behavioral change trajectories[cite: 1].



#### **3. Global Development & Measurement Invariance (LEVANTE Project)**
[cite_start]As a Postdoctoral Scholar at Stanford, I work on the LEVANTE project to create internationalized measures of learning for children[cite: 1].
* [cite_start]My focus is on **measurement invariance** and statistical methods for modeling developmental change across diverse cultural contexts[cite: 1].
* [cite_start]We aim to validate core cognitive tasks that are robust to cross-linguistic and cross-site variations[cite: 1].

#### **4. Adaptive Measurement & Digital Innovation**
* [cite_start]**CAT Fairness**: Researching calibration error mitigation and robust stopping rules in computer-adaptive testing[cite: 1].
* **Silver Tech**: Applying psychometric principles to the development of "Silver Hair" (银发产品) digital solutions, focusing on reward mechanisms and data collection for the aging population.

---

### Methods & Technical Toolbelt

[cite_start]I utilize a mix of Bayesian and frequentist frameworks to solve measurement challenges, leaning heavily on open-science and "GitHub-first" workflows[cite: 1].

* [cite_start]**Models**: Multidimensional IRT (mIRT), Many-Facet Rasch Models (MFRM), Bayesian GMM, and Differential Item Functioning (DIF)[cite: 1, 2].
* [cite_start]**AI/NLP**: LLM evaluation (GPT-4), NLP-based scoring frameworks, and automated prompt engineering[cite: 1, 2].
* [cite_start]**Statistical Software**: Expert proficiency in **R** (Stan, ggplot2, Shiny), **Python**, SQL, and **Mplus**[cite: 1, 2].
* [cite_start]**Reproducibility**: Quarto, LaTeX, and Git/GitHub version control for collaborative manuscript preparation[cite: 1].
